from __future__ import print_function
from __future__ import division
from __future__ import absolute_import
import tensorflow as tf
import numpy as np
import config
import sys

FLAGS = config.flags.FLAGS


#The function first generates an encoder network for each predator agent's observation 
# using the encoder_network() function. It then generates a decoder network that takes in the encoded observations
#  of all predator agents and the communication schedule for the current step and generates a concatenated 
# communication message for all predator agents using the decode_concat_network() function.

def generate_comm_network(obs_list, obs_dim_per_unit, action_dim, n_agent, trainable=True, share=False):
    actions = list()
    h_num = 32

    capacity = FLAGS.capa 



        

    # for full communicattion use this part else comment this part:
    obs_list= tf.concat(obs_list, axis=-1)

    # Generate actor
    scope = "comm"
    for i in range(n_agent):
        if not FLAGS.s_share:
            scope = "comm" + str(i)

        with tf.compat.v1.variable_scope(scope):

            agent_actor = comm_encoded_obs(obs_list, action_dim, trainable)
        actions.append(agent_actor)

    return tf.concat(actions, axis=-1)

#  the function generates an actor network for each predator agent's communication action
#  using the comm_encoded_obs() function, which takes in the observation of the predator
#  agent, the concatenated communication message generated by the decoder network, and generates a
#  probability distribution over communication actions for the predator agent.
#  encoder_network() is used to encode the observation of each predator agent into 
#  a lower-dimensional representation that can be used as input to the decoder network.
#  It takes in the observation tensor e_input and generates an encoded representation of size out_
#  dim using fully connected layers with h_num hidden units and h_level layers. The output 
#  of encoder_network() is a tensor of shape (batch_size, out_dim).

def comm_encoded_obs(obs, action_dim, trainable=True):
    h_num=32
    hidden_1 = tf.keras.layers.Dense(units=h_num, activation=tf.nn.relu,
                                     kernel_initializer=tf.random_normal_initializer(0., .1),  # weights
                                     bias_initializer=tf.constant_initializer(0.1),  # biases
                                     use_bias=True, trainable=trainable, name='sender_1')(obs)
    hidden_2 = tf.keras.layers.Dense(units=h_num, activation=tf.nn.relu,
                                     kernel_initializer=tf.random_normal_initializer(0., .1),  # weights
                                     bias_initializer=tf.constant_initializer(0.1),  # biases
                                     use_bias=True, trainable=trainable, name='sender_2')(hidden_1)

    hidden_3 = tf.keras.layers.Dense(units=h_num, activation=tf.nn.relu,
                                     kernel_initializer=tf.random_normal_initializer(0., .1),  # weights
                                     bias_initializer=tf.constant_initializer(0.1),  # biases
                                     use_bias=True, trainable=trainable, name='sender_3')(hidden_2)

    a = tf.keras.layers.Dense(units=action_dim, activation=tf.nn.softmax,
                              kernel_initializer=tf.random_normal_initializer(0., .1),  # weights
                              bias_initializer=tf.constant_initializer(0.1),  # biases
                              use_bias=True, trainable=trainable, name='sender_4')(hidden_3)
    return a

# Encoding
# #used to generate a probability distribution over communication actions for 
# # each predator agent, given its observation
# #  and the concatenated communication message generated by the decoder network
# def encoder_network(e_input, out_dim, h_num, h_level, name="encoder", trainable=True):
    
#     hidden = e_input
#     for i in range(h_level):
#         hidden = tf.keras.layers.Dense(units=h_num, activation=tf.nn.relu,
#                                        kernel_initializer=tf.random_normal_initializer(0., .1),  # weights
#                                        bias_initializer=tf.constant_initializer(0.1),  # biases
#                                        use_bias=True, trainable=trainable, name=name+str(i))(hidden)

#     ret = tf.keras.layers.Dense(units=out_dim, activation=tf.nn.relu,
#                                 kernel_initializer=tf.random_normal_initializer(0., .1),  # weights
#                                 bias_initializer=tf.constant_initializer(0.1),  # biases
#                                 use_bias=True, trainable=trainable, name=name+"_out")(hidden)
#     return ret

# def decode_concat_network(m_input_list, schedule, capacity, out_dim):

#     inp = tf.stack(m_input_list, axis=-2)
#     masked_msg = tf.boolean_mask(tf.reshape(inp, [-1, capacity]), tf.reshape(tf.cast(schedule, tf.bool), [-1]))
#     return tf.reshape(masked_msg, [-1, FLAGS.s_num * capacity], name='scheduled')
